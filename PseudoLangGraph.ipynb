{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3515f20-bd17-406b-9bd3-fb533dd423ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain pymongo -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f84ab80-a738-4aee-aa29-82752c79b16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.tools import tool # tools for our llm\n",
    "from langchain.tools.render import render_text_description # to describe tools as a string \n",
    "from langchain_core.output_parsers import JsonOutputParser # ensure JSON input for tools\n",
    "from operator import itemgetter # to retrieve specific items in our chain.\n",
    "\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ae13d2a-88c1-4f74-b7e0-4a66d92d51b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('localhost', 27017)\n",
    "database = client['LangChain_Intento4']\n",
    "collection = database['lenguajes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a57a97c4-634a-4e27-bd34-4dba9edb9e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the LLM which will power our application.\n",
    "model = Ollama(model='llama3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0416a80a-dc76-431a-a7b2-08acb1650af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05265c04-5f0e-449e-9075-faf727e17066",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def converse(input: dict) -> str:\n",
    "    \"Provide a natural language response using the user input.\"\n",
    "    print(input)\n",
    "    user_input = input[\"dict\"]\n",
    "    return model.invoke(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7775430f-8b29-4d7c-9ce4-962763dcd1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def conversacion(input: str) -> str:\n",
    "    \"Provide a natural language response using the user input.\"\n",
    "    return model.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a97b02d-2dcb-41c5-a8f2-6d0d563a507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def schedule_an_appointment(input: dict) -> str:\n",
    "    \"Begin the task of scheduling an appointment.\"\n",
    "\n",
    "    user_input = input[\"input\"]\n",
    "    chat_history = []\n",
    "    client = MongoClient('localhost', 27017)\n",
    "    database = client['LangChain_Intento4']\n",
    "    collection = database['lenguajes']\n",
    "\n",
    "    prompt_template_appointment = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"Eres un AI que agenda citas, me debes ir preguntando mi información hasta obtener lo siguiente:\n",
    "            - nombre\n",
    "            - email\n",
    "            - horario de cita (día de la semana, día del mes, mes y hora), haz esto mensaje tras mensaje.\n",
    "            \n",
    "            Solamente cuando hayas obtenido todo, retornarás los datos en forma de diccionario: \n",
    "            'nombre': <nombre>, 'email': <email>, 'cita': <horario de la cita en MM/DD/2024 HH:MM>\n",
    "            No retornes nada extra más que eso, solamente el diccionario, ninguna palabra más.\"\"\",\n",
    "        ),\n",
    "\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ])\n",
    "\n",
    "    chain = prompt_template_appointment | model\n",
    "    \n",
    "    while True:\n",
    "        pregunta = input(\"You: \")\n",
    "        if pregunta == \"bye\":\n",
    "            return\n",
    "        # response = llm.invoke(question\n",
    "        response = chain.invoke({\"input\": pregunta, \"chat_history\": chat_history})\n",
    "        chat_history.append(HumanMessage(content=pregunta))\n",
    "        chat_history.append(SystemMessage(content=response))\n",
    "        print(\"-\"*50)\n",
    "        print(\"AI: \" + response)\n",
    "\n",
    "        #datos_iniciales = response[-1].content\n",
    "        datos_iniciales = response\n",
    "        if datos_iniciales.startswith(\"{\"):\n",
    "            print(\"---------------out--------------\")\n",
    "            datos_diccionario = eval(datos_iniciales)\n",
    "            print(type(datos_diccionario))\n",
    "            print(datos_diccio-------out---nario)\n",
    "            user_nombre = datos_diccionario['nombre']\n",
    "            print(user_nombre)\n",
    "            user_email = datos_diccionario['email']\n",
    "            print(user_email)\n",
    "            user_cita = datos_diccionario['cita']\n",
    "            print(user_cita)\n",
    "            print(\"---------------out--------------\")\n",
    "\n",
    "            confirmacion = \"Preguntame si quiero confirmar la cita, si te digo que no, pregúntame qué quiero modificar, lo modificas y vuelves a retornar el diccionario. Si te digo que sí, retorna solamente True, nada más\"\n",
    "            response = chain.invoke({\"input\": confirmacion, \"chat_history\": chat_history}) #aqui el chat nos pregunta si confirmamos\n",
    "            chat_history.append(HumanMessage(content=confirmacion)) #guardar confirmacion\n",
    "            chat_history.append(SystemMessage(content=response)) # guardar accion IA\n",
    "            print(\"AI: \" + response)           \n",
    "            pregunta = input(\"You: \") #aquí respondemos a si confirmamos o no\n",
    "            response = chain.invoke({\"input\": pregunta, \"chat_history\": chat_history}) #aqui imprime True\n",
    "            chat_history.append(HumanMessage(content=pregunta)) # guardar nuestra confirmacion\n",
    "            chat_history.append(SystemMessage(content=response)) # guardar True\n",
    "            if str(response) == \"True\":\n",
    "                print(\"---------------out--------------\")\n",
    "                collection.insert_one({\"name\":user_nombre, \"email\": user_email, \"cita\": user_cita})\n",
    "                print(\"cita agendada\")\n",
    "                print(\"-------------------\")\n",
    "                return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe08c1ed-15c0-4aec-9550-7182cdc083c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def agendar_cita(input: str) -> str:\n",
    "    \"Begin the task of scheduling an appointment.\"\n",
    "\n",
    "    user_input = input\n",
    "    chat_history = []\n",
    "    client = MongoClient('localhost', 27017)\n",
    "    database = client['LangChain_Intento4']\n",
    "    collection = database['lenguajes']\n",
    "\n",
    "    prompt_template_appointment = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"Eres un AI que agenda citas, me debes ir preguntando mi información hasta obtener lo siguiente:\n",
    "            - nombre\n",
    "            - email\n",
    "            - horario de cita (día de la semana, día del mes, mes y hora), haz esto mensaje tras mensaje.\n",
    "            \n",
    "            Solamente cuando hayas obtenido todo, retornarás los datos en forma de diccionario: \n",
    "            'nombre': <nombre>, 'email': <email>, 'cita': <horario de la cita en MM/DD/2024 HH:MM>\n",
    "            No retornes nada extra más que eso, solamente el diccionario, ninguna palabra más.\"\"\",\n",
    "        ),\n",
    "\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ])\n",
    "\n",
    "    chain = prompt_template_appointment | model\n",
    "    inicializador = chain.invoke({\"input\": user_input, \"chat_history\": chat_history})\n",
    "    chat_history.append(SystemMessage(content=inicializador))\n",
    "    while True:\n",
    "        pregunta = input(\"You: \")\n",
    "        if pregunta == \"bye\":\n",
    "            return\n",
    "        # response = llm.invoke(question\n",
    "        response = chain.invoke({\"input\": pregunta, \"chat_history\": chat_history})\n",
    "        chat_history.append(HumanMessage(content=pregunta))\n",
    "        chat_history.append(SystemMessage(content=response))\n",
    "        print(\"-\"*50)\n",
    "        print(\"AI: \" + response)\n",
    "\n",
    "        #datos_iniciales = response[-1].content\n",
    "        datos_iniciales = response\n",
    "        if datos_iniciales.startswith(\"{\"):\n",
    "            print(\"---------------out--------------\")\n",
    "            datos_diccionario = eval(datos_iniciales)\n",
    "            print(type(datos_diccionario))\n",
    "            print(datos_diccio-------out---nario)\n",
    "            user_nombre = datos_diccionario['nombre']\n",
    "            print(user_nombre)\n",
    "            user_email = datos_diccionario['email']\n",
    "            print(user_email)\n",
    "            user_cita = datos_diccionario['cita']\n",
    "            print(user_cita)\n",
    "            print(\"---------------out--------------\")\n",
    "\n",
    "            confirmacion = \"Preguntame si quiero confirmar la cita, si te digo que no, pregúntame qué quiero modificar, lo modificas y vuelves a retornar el diccionario. Si te digo que sí, retorna solamente True, nada más\"\n",
    "            response = chain.invoke({\"input\": confirmacion, \"chat_history\": chat_history}) #aqui el chat nos pregunta si confirmamos\n",
    "            chat_history.append(HumanMessage(content=confirmacion)) #guardar confirmacion\n",
    "            chat_history.append(SystemMessage(content=response)) # guardar accion IA\n",
    "            print(\"AI: \" + response)           \n",
    "            pregunta = input(\"You: \") #aquí respondemos a si confirmamos o no\n",
    "            response = chain.invoke({\"input\": pregunta, \"chat_history\": chat_history}) #aqui imprime True\n",
    "            chat_history.append(HumanMessage(content=pregunta)) # guardar nuestra confirmacion\n",
    "            chat_history.append(SystemMessage(content=response)) # guardar True\n",
    "            if str(response) == \"True\":\n",
    "                print(\"---------------out--------------\")\n",
    "                collection.insert_one({\"name\":user_nombre, \"email\": user_email, \"cita\": user_cita})\n",
    "                print(\"cita agendada\")\n",
    "                print(\"-------------------\")\n",
    "                return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66b8ce15-a5b7-44df-b8ef-100e67ba2b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converse: converse(input: dict) -> str - Provide a natural language response using the user input.\n",
      "conversacion: conversacion(input: str) -> str - Provide a natural language response using the user input.\n",
      "schedule_an_appointment: schedule_an_appointment(input: dict) -> str - Begin the task of scheduling an appointment.\n"
     ]
    }
   ],
   "source": [
    "tools = [converse,  conversacion, schedule_an_appointment]\n",
    "rendered_tools = render_text_description(tools)\n",
    "print(rendered_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74b8e5f6-376f-48cf-b045-493dc2348cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"You are an chatbot that has access to the following set of tools.\n",
    "Here are the names and descriptions for each tool:\n",
    "\n",
    "{rendered_tools}\n",
    "Given the user input, return the name and input of the tool to use.\n",
    "Return your response as a JSON blob with 'name' and 'arguments' keys.\n",
    "The value associated with the 'arguments' key should be a dictionary of parameters.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51a8a2ba-6732-407c-82f2-3887d90c0bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_main = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt), \n",
    "         MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "         (\"user\", \"{input}\"),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3173dbbe-e06e-448b-8626-351230bafe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function which returns the chosen tool\n",
    "# to be run as part of the chain.\n",
    "def tool_chain(model_output):\n",
    "    tool_map = {tool.name: tool for tool in tools}\n",
    "    if \"name\" not in model_output:\n",
    "        raise KeyError(\"The model_output dictionary does not contain the 'name' key.\")\n",
    "    chosen_tool = tool_map[model_output[\"name\"]]\n",
    "    return itemgetter(\"arguments\") | chosen_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41eecbfe-ef95-4d0f-99be-89479685920a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_main = prompt_template_main | model | JsonOutputParser() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa019c5a-d6a9-4da9-830a-a7b0c9418f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Write a message:  hola\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tool': 'conversacion', 'arguments': {'input': 'Hola'}}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Write a message:  quiero agendar una cita\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'schedule_an_appointment', 'arguments': {'input': {}}}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Write a message:  por favor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'conversacion', 'arguments': {'input': 'hola por favor'}}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Write a message:  quiero agendar una cita\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'schedule_an_appointment', 'arguments': {'hora': '', 'día': '', 'asunto': ''}}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m----> 2\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrite a message: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m     response \u001b[38;5;241m=\u001b[39m chain_main\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m: user_input, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m\"\u001b[39m: chat_history})\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m#chat_history.append(HumanMessage(content=user_input))\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m#chat_history.append(SystemMessage(content=response))\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\LangChain_Intento2_Llama3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1262\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1260\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[0;32m   1263\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[0;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1266\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1267\u001b[0m )\n",
      "File \u001b[1;32m~\\.conda\\envs\\LangChain_Intento2_Llama3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1305\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1303\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1304\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"Write a message: \")\n",
    "    response = chain_main.invoke({'input': user_input, \"chat_history\": chat_history})\n",
    "    #chat_history.append(HumanMessage(content=user_input))\n",
    "    #chat_history.append(SystemMessage(content=response))\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e5fe8b-9e62-44e9-a2ce-b70893a579c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a34da0-c609-4b5b-ba0b-37146bd0c35d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
