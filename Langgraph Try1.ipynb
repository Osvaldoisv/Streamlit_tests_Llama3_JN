{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b779ea5d-1fa8-4a32-8b41-d5da3a4988d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain streamlit -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc3f1223-8d8c-46c9-b2a9-9c58ef4e23ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.chat_models import ChatOllama\n",
    "import streamlit as st # to render the user interface.\n",
    "from langchain_community.llms import Ollama # to use Ollama llms in langchain\n",
    "from langchain_core.prompts import ChatPromptTemplate # crafts prompts for our llm\n",
    "from langchain_community.chat_message_histories import\\\n",
    "StreamlitChatMessageHistory # stores message history\n",
    "from langchain_core.tools import tool # tools for our llm\n",
    "from langchain.tools.render import render_text_description # to describe tools as a string \n",
    "from langchain_core.output_parsers import JsonOutputParser # ensure JSON input for tools\n",
    "from operator import itemgetter # to retrieve specific items in our chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6902242a-4eff-4008-adeb-ef0237367c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the LLM which will power our application.\n",
    "model = Ollama(model='llama3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b59a4fa-c789-408f-9671-d41884a4f3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add(first: int, second: int) -> int:\n",
    "    \"Add two integers.\"\n",
    "    return first + second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3025507a-d5a7-4bcd-829b-a06ee46827f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add\n",
      "add(first: int, second: int) -> int - Add two integers.\n",
      "{'first': {'title': 'First', 'type': 'integer'}, 'second': {'title': 'Second', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "print(add.name)\n",
    "print(add.description)\n",
    "print(add.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f99699da-84e9-4707-8306-653ee7579ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add.invoke({'first':3, 'second':6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40e9ae24-1aed-4986-bbcc-b2cef4a4cf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply(first: int, second: int) -> int:\n",
    "    \"\"\"Multiply two integers together.\"\"\"\n",
    "    return first * second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9456ee6a-b42c-4661-b93f-d2bd7ed04850",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def converse(input: str) -> str:\n",
    "    \"Provide a natural language response using the user input.\"\n",
    "    return model.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31c13328-1770-45ab-b317-025b333333a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add: add(first: int, second: int) -> int - Add two integers.\n",
      "multiply: multiply(first: int, second: int) -> int - Multiply two integers together.\n",
      "converse: converse(input: str) -> str - Provide a natural language response using the user input.\n"
     ]
    }
   ],
   "source": [
    "tools = [add, multiply, converse]\n",
    "rendered_tools = render_text_description(tools)\n",
    "print(rendered_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd0c7e7a-e10b-4989-bbd1-366d70695b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"You are an assistant that has access to the following set of tools.\n",
    "Here are the names and descriptions for each tool:\n",
    "\n",
    "{rendered_tools}\n",
    "Given the user input, return the name and input of the tool to use.\n",
    "Return your response as a JSON blob with 'name' and 'arguments' keys.\n",
    "The value associated with the 'arguments' key should be a dictionary of parameters.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67804b4e-68ad-4f88-901a-1c7a661c25cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_prompt), (\"user\", \"{input}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "402ee073-fa9a-4a67-9fa2-f6765d8462f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95d4b641-d2c2-4210-b74b-d8d800dc23d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'multiply', 'arguments': {'first': 3, 'second': 23}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'input': 'What is 3 times 23'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f40c0f1-0b83-4897-9627-2892fe96edd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tool': 'converse',\n",
       " 'arguments': {'input': \"I'm doing well, thanks for asking. How about you?\"}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'input': 'How are you today?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46123a90-d011-40a9-b980-72d0c5c10b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function which returns the chosen tool\n",
    "# to be run as part of the chain.\n",
    "def tool_chain(model_output):\n",
    "    tool_map = {tool.name: tool for tool in tools}\n",
    "    chosen_tool = tool_map[model_output[\"name\"]]\n",
    "    return itemgetter(\"arguments\") | chosen_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acea06bc-56ac-4f4b-8524-a4d0185aa52d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | JsonOutputParser() | tool_chain\n",
    "chain.invoke({'input': 'What is 3 times 23'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae6f1348-7187-4c32-81a5-4fce4ad773dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'key' not in st.session_state:\n",
    "    st.session_state['key'] = 'langchain_messages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6c72ff6-c4ae-4072-9aec-9d99483cf672",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'st.session_state has no key \"langchain_messages\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\.conda\\envs\\LangChain_Intento2_Llama3\\Lib\\site-packages\\streamlit\\runtime\\state\\session_state.py:411\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem(widget_id, key)\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\LangChain_Intento2_Llama3\\Lib\\site-packages\\streamlit\\runtime\\state\\session_state.py:456\u001b[0m, in \u001b[0;36mSessionState._getitem\u001b[1;34m(self, widget_id, user_key)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;66;03m# We'll never get here\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Set up message history.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m msgs \u001b[38;5;241m=\u001b[39m StreamlitChatMessageHistory(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlangchain_messages\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(msgs\u001b[38;5;241m.\u001b[39mmessages) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m      4\u001b[0m     msgs\u001b[38;5;241m.\u001b[39madd_ai_message(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI can add, multiply, or just chat! How can I help you?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\LangChain_Intento2_Llama3\\Lib\\site-packages\\langchain_community\\chat_message_histories\\streamlit.py:25\u001b[0m, in \u001b[0;36mStreamlitChatMessageHistory.__init__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m st\u001b[38;5;241m.\u001b[39msession_state:\n\u001b[0;32m     24\u001b[0m     st\u001b[38;5;241m.\u001b[39msession_state[key] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_messages \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39msession_state[key]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key \u001b[38;5;241m=\u001b[39m key\n",
      "File \u001b[1;32m~\\.conda\\envs\\LangChain_Intento2_Llama3\\Lib\\site-packages\\streamlit\\runtime\\state\\session_state_proxy.py:90\u001b[0m, in \u001b[0;36mSessionStateProxy.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     88\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(key)\n\u001b[0;32m     89\u001b[0m require_valid_user_key(key)\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m get_session_state()[key]\n",
      "File \u001b[1;32m~\\.conda\\envs\\LangChain_Intento2_Llama3\\Lib\\site-packages\\streamlit\\runtime\\state\\safe_session_state.py:93\u001b[0m, in \u001b[0;36mSafeSessionState.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_yield_callback()\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state[key]\n",
      "File \u001b[1;32m~\\.conda\\envs\\LangChain_Intento2_Llama3\\Lib\\site-packages\\streamlit\\runtime\\state\\session_state.py:413\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem(widget_id, key)\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m--> 413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(_missing_key_error_message(key))\n",
      "\u001b[1;31mKeyError\u001b[0m: 'st.session_state has no key \"langchain_messages\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization'"
     ]
    }
   ],
   "source": [
    "# Set up message history.\n",
    "msgs = StreamlitChatMessageHistory(key=\"langchain_messages\")\n",
    "if len(msgs.messages) == 0:\n",
    "    msgs.add_ai_message(\"I can add, multiply, or just chat! How can I help you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fbc7e7-bfbc-4bb7-8aff-0dafab021590",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
